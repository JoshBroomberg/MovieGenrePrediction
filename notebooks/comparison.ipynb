{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Markdown as md\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Features\n",
    "\n",
    "We are currently using the following models to train against the dataset with the associated feature engineering:\n",
    "1. C-SVM\n",
    "    - The overviews are using a **bag of words** model and have been vectorized and transformed using **TF_IDF**.\n",
    "2. Naive Bayes\n",
    "    - The overviews are using a **bag of words** model and have been vectorized with a **Count Vectorizer**.\n",
    "3. Simple neural network (not deep)\n",
    "    - The overviews were tokenized with a **white space tokenizer**. Stop words were removed. Overviews were treated as **bag of words**, which each word being converted to a vector, using the GoogleNews-vectors-negative300.bin model.  The **arithmetic mean** of the words represented the overview. Taking the top 3 genres predicted for each movie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{ROOT}/data/processed/genre_id_to_name_dict.pkl','rb') as f:\n",
    "    genre_id_to_name=pickle.load(f)  \n",
    "\n",
    "genre_names=list(genre_id_to_name.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{ROOT}/models/model_scores.json\", \"r\") as f:\n",
    "    scores = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{ROOT}/data/processed/target_test.pkl','rb') as f:\n",
    "    target_test=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with Raw Bag of Word Features\n",
    "\n",
    "#### Metrics for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n\n         Action       0.55      0.54      0.55        48\n      Adventure       0.41      0.58      0.48        31\n      Animation       0.50      0.42      0.46        31\n         Comedy       0.67      0.60      0.63        87\n          Crime       0.50      0.34      0.41        29\n    Documentary       0.65      0.64      0.64        61\n          Drama       0.45      0.42      0.43        50\n         Family       0.30      0.33      0.32        18\n        Fantasy       0.25      0.08      0.12        12\n        History       0.50      0.49      0.50        53\n         Horror       0.52      0.44      0.48        25\n          Music       0.59      0.71      0.65        14\n        Mystery       0.55      0.50      0.52        34\n        Romance       0.41      0.29      0.34        24\nScience Fiction       0.33      0.50      0.40        14\n       TV Movie       0.44      0.47      0.45        30\n       Thriller       0.48      0.42      0.45        38\n            War       0.76      0.59      0.67        22\n        Western       0.25      0.14      0.18        21\n\n      micro avg       0.52      0.48      0.50       642\n      macro avg       0.48      0.45      0.46       642\n   weighted avg       0.52      0.48      0.50       642\n    samples avg       0.49      0.49      0.46       642\n\n"
     ]
    }
   ],
   "source": [
    "with open(f'{ROOT}/models/classifier_nb.pkl','rb') as f:\n",
    "    classifnb = pickle.load(f)\n",
    "\n",
    "with open(f'{ROOT}/data/processed/raw_count_features_test.pkl','rb') as f:\n",
    "    raw_count_features_test=pickle.load(f)\n",
    "\n",
    "predsnb=classifnb.predict(raw_count_features_test)\n",
    "print (classification_report(target_test, predsnb, target_names=genre_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall for the overall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\nPrecision: 0.493351302785265\n\nRecall: 0.4944182389937107\n"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nb_scores = scores[\"naive_bayes\"]\n",
    "\n",
    "md('''\n",
    "Precision: {prec_mean}\n",
    "\n",
    "Recall: {rec_mean}\n",
    "'''.format(prec_mean=nb_scores[\"prec\"], rec_mean=nb_scores[\"rec\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-SVM with TF-IDF features\n",
    "\n",
    "#### Metrics for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n\n         Action       0.00      0.00      0.00        48\n      Adventure       0.27      0.52      0.35        31\n      Animation       0.00      0.00      0.00        31\n         Comedy       0.58      0.57      0.58        87\n          Crime       0.42      0.38      0.40        29\n    Documentary       0.60      0.74      0.66        61\n          Drama       0.00      0.00      0.00        50\n         Family       0.44      0.39      0.41        18\n        Fantasy       0.25      0.08      0.12        12\n        History       0.46      0.55      0.50        53\n         Horror       0.58      0.56      0.57        25\n          Music       0.73      0.79      0.76        14\n        Mystery       0.47      0.47      0.47        34\n        Romance       0.35      0.38      0.36        24\nScience Fiction       0.43      0.43      0.43        14\n       TV Movie       0.40      0.27      0.32        30\n       Thriller       0.47      0.50      0.49        38\n            War       0.75      0.68      0.71        22\n        Western       0.29      0.19      0.23        21\n\n      micro avg       0.49      0.41      0.44       642\n      macro avg       0.39      0.39      0.39       642\n   weighted avg       0.39      0.41      0.39       642\n    samples avg       0.49      0.44      0.44       642\n\n"
     ]
    }
   ],
   "source": [
    "with open(f'{ROOT}/models/classifier_svc.pkl','rb') as f:\n",
    "    svc_classifier=pickle.load(f)\n",
    "\n",
    "with open(f'{ROOT}/data/processed/tfidf_count_features_test.pkl','rb') as f:\n",
    "    tfidf_count_features=pickle.load(f)\n",
    "\n",
    "predstfidf=svc_classifier.predict(tfidf_count_features)\n",
    "print(classification_report(target_test, predstfidf, target_names=genre_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall for the overall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\nPrecision: 0.48875786163522\n\nRecall: 0.44017295597484274\n"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "svc_scores = scores[\"svc\"]\n",
    "\n",
    "md('''\n",
    "Precision: {prec_mean}\n",
    "\n",
    "Recall: {rec_mean}\n",
    "'''.format(prec_mean=svc_scores[\"prec\"], rec_mean=svc_scores[\"rec\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network with Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "with open(f'{ROOT}/data/processed/w2v_features_test.pkl','rb') as f:\n",
    "    w2v_features=pickle.load(f)\n",
    "\n",
    "w2v_nn = keras.models.load_model(f\"{ROOT}/models/classifier_nn.h5\")\n",
    "with open(f'{ROOT}/models/mlb.pkl','rb') as f:\n",
    "    mlb=pickle.load(f)\n",
    "\n",
    "# score = w2v_nn.evaluate(w2v_features, target_test, batch_size=249)\n",
    "Y_preds=w2v_nn.predict(w2v_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall for the overall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\nPrecision: 0.5172955974842767\n\nRecall: 0.5558176100628931\n"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "nn_scores = scores[\"neural_network\"]\n",
    "\n",
    "md('''\n",
    "Precision: {prec_mean}\n",
    "\n",
    "Recall: {rec_mean}\n",
    "'''.format(prec_mean=nn_scores[\"prec\"], rec_mean=nn_scores[\"rec\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}